# Lexical Analysis
From _Compilers: Principles, Techniques, and Tools_ by Alfred V. Aho, Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman:
> The lexical analyzer is the first phase of a compiler. Its main task is to read
> the input characters and produce as output a sequence of tokens that the parser
> uses for syntax analysis.

TODO-DOC

 ## Enum Attributes
 These attributes apply to the enum
 #### `ignore`
 This is used to define patterns to ignore when lexing. A common example is whitespaces.
 The pattern is a regular expression that must start with "^" and does not match the empty
 string.
 ```rust
 use teleparse::prelude::*;

 #[teleparse_derive(TokenType)]
 #[teleparse(ignore(r#"^\s+"#))]
 pub enum MyToken {
     // ...
 # #[teleparse(regex(r#"^\d+"#))]
 # Integer,
 }
 ```
 If the pattern is complicated, you can use multiple regular expressions are well. Use `,` to separate them (i.e. `ignore(r#"^\s+"#, r#"^\d+"#)`)

 ## Variant Attributes
 These attributes apply to the variants
 ### `terminal`
 Used to generate terminal [`SyntaxTree`](crate::SyntaxTree) implementation for tokens. There
 are 2 forms:
 - `terminal(XXX)` for matching any string content
 ```rust
 use teleparse::prelude::*;

 #[teleparse_derive(TokenType)]
 pub enum MyToken {
     #[teleparse(regex(r#"^\d+"#), terminal(Integer))]
     Integer,
 }
 derive_root!(Integer); // only needed for `Integer::parse`

 # fn main() {
 let source = "123";
 assert_eq!(
     Integer::parse(source), // `Integer` is generated by the macro
     Some(Integer(Token::new((0, 3), MyToken::Integer)))
 );
 # }
 ```
 - `terminal(XXX = "literal")` matching specific literal content
 ```rust
 use teleparse::prelude::*;

 #[teleparse_derive(TokenType)]
 pub enum MyToken {
     #[teleparse(terminal(Zero = "0"))]
     Integer,
 }
 derive_root!(Zero); // only needed for `Zero::parse`

 # fn main() {
 let source = "0";
 assert_eq!(
     Zero::parse(source),
     Some(Zero(Token::new((0, 1), MyToken::Integer)))
 );
 # }
 ```
 There are static checks built-in to ensure that the literal is unique.
 ```compile_fail
 use teleparse::prelude::*;

 #[teleparse_derive(TokenType)]
 pub enum MyToken {
     // fail! Two terminals matches "0" - This will generate 2 terminals that do the same thing
     #[teleparse(terminal(Zero = "0", Another = "0"))]
     Integer,
 }
 ```
 Likewise, there can only be one terminal without a literal value.
 Having multiple is likely a mistake because they are interchangable in the AST.
 ```compile_fail
 use teleparse::prelude::*;

 #[teleparse_derive(TokenType)]
 pub enum MyToken {
     // fail! these two terminals are interchangable. DRY!
     #[teleparse(regex(r"^\d+"), terminal(Integer, FancyInteger))]
     Integer,
 }
 ```

 ### `regex`
 Used to define the regex(es) used to match a token type when the pattern
 cannot be inferred from `terminal`.
 The rule can be inferred if all `terminal` variants have a literal value.
 In this case, definting the regex will be redundant and will cause an error:
 ```compile_fail
 # use teleparse::prelude::*;
 # #[teleparse_derive(TokenType)]
 # pub enum TokenType {
 #[teleparse(terminal(
     OpAdd = "+", 
     OpSub = "-", 
     OpMul = "*", 
     OpDiv = "/",
 ), regex(r#"^[\+\-\*/]"#))] // error! the rule can already be inferred
 Operator,
 # }
 ```
 Likewise, if the rule cannot be inferred, then `regex` is required.

 The following example generates 2 structs: `Word` and `Secret`.
 Because only `Secret` has a literal to match, a regex is required
 to be able to match `Word` as well.
 ```rust
 use teleparse::prelude::*;

 #[teleparse_derive(TokenType)]
 pub enum MyToken {
     #[teleparse(regex(r#"^\w+"#), terminal(Word, Secret = "rust"))]
     Word,
 }
 derive_root!(Word);
 derive_root!(Secret);

 # fn main() {
 let source = "rust";
 // Word can be parsed
 assert_eq!(
     Word::parse(source),
     Some(Word(Token::new((0, 4), MyToken::Word)))
 );
 // so is Secret
 assert_eq!(
     Secret::parse(source),
     Some(Secret(Token::new((0, 4), MyToken::Word)))
 );
 // but not with others
 let source = "javascript";
 assert_eq!(
     Word::parse(source),
     Some(Word(Token::new((0, 10), MyToken::Word)))
 );
 assert_eq!(
     Secret::parse(source),
     None
 );
 # }
 ```
 There are static checks for the regex as well:
 ```compile_fail
 # use teleparse::prelude::*;
 # #[teleparse_derive(TokenType)]
 # pub enum MyToken {
 // fail! invalid regex
 #[teleparse(regex(r#"^\"#))]
 Invalid, 
 # }
 ```
 ```compile_fail
 # use teleparse::prelude::*;
 # #[teleparse_derive(TokenType)]
 # pub enum MyToken {
 // fail! the regex must start with ^ to matching something 
 // in the beginning of the remaning input
 #[teleparse(regex(r#"\w+"#))]
 MatchMiddle, 
 # }
 ```
 ```compile_fail
 # use teleparse::prelude::*;
 # #[teleparse_derive(TokenType)]
 # pub enum MyToken {
 // fail! the regex must not match the empty string
 #[teleparse(regex(r#"^"#))]
 MatchEmpty, 
 # }
 ```
 ```compile_fail
 # use teleparse::prelude::*;
 # #[teleparse_derive(TokenType)]
 # pub enum MyToken {
 // fail! if a token matches the regex, it would not be able to match the terminal
 #[teleparse(regex(r#"^key"#), terminal(Key, Keyboard = "keyboard"))]
 DoesNotMatchTerminal, 
 # }
 ```
